tech
execs
say
they're
acting
faster
on
extremist
content
from
left
monika
bickert
head
of
global
policy
management
at
facebook
nick
pickles
public
policy
director
for
twitter
derek
slater
global
director
of
information
policy
at
google
and
anti-defamation
league
senior
vice
president
of
programs
george
selim
testify
before
the
senate
commerce
science
and
transportation
committee
on
how
internet
and
social
media
companies
are
prepared
to
thwart
terrorism
and
extremism
wednesday
sept
on
capitol
hill
in
washington
j.
scott
applewhite
associated
press
washington
executives
of
facebook
google
and
twitter
told
congress
on
wednesday
that
they've
gotten
better
and
faster
at
detecting
and
removing
violent
extremist
content
on
their
social
media
platforms
in
the
face
of
mass
shootings
fueled
by
hatred
questioned
at
a
hearing
by
the
senate
commerce
committee
the
executives
said
they
are
spending
money
on
technology
to
improve
their
ability
to
flag
extremist
content
and
taking
the
initiative
to
reach
out
to
law
enforcement
authorities
to
try
to
head
off
potential
violent
incidents
we
will
continue
to
invest
in
the
people
and
technology
to
meet
the
challenge
said
derek
slater
google's
director
of
information
policy
the
lawmakers
want
to
know
what
the
companies
are
doing
to
remove
hate
speech
from
their
platforms
and
how
they
are
coordinating
with
law
enforcement
we
are
experiencing
a
surge
of
hate
social
media
is
used
to
amplify
that
hate
said
sen
maria
cantwell
of
washington
state
the
panel's
senior
democrat
the
company
executives
testified
that
their
technology
is
improving
for
identifying
and
taking
down
suspect
content
faster
of
the
million
videos
removed
from
google's
youtube
in
the
second
quarter
of
the
year
were
flagged
by
a
machine
using
artificial
intelligence
and
many
of
them
were
taken
down
before
they
got
a
single
view
slater
said
after
the
february
high
school
shooting
in
florida
that
killed
people
google
began
to
proactively
reach
out
to
law
enforcement
authorities
to
see
how
they
can
better
coordinate
slater
said
nikolas
cruz
the
shooting
suspect
had
posted
on
a
youtube
page
beforehand
i'm
going
to
be
a
professional
school
shooter
authorities
said
word
came
this
week
from
facebook
that
it
will
work
with
law
enforcement
organizations
to
train
its
ai
systems
to
recognize
videos
of
violent
events
as
part
of
a
broader
effort
to
crack
down
on
extremism
facebook's
ai
systems
were
unable
to
detect
livestreamed
video
of
the
mosque
shootings
in
new
zealand
in
march
that
killed
people
the
self-professed
white
supremacist
accused
of
the
shootings
had
livestreamed
the
attack
the
effort
will
use
bodycam
footage
of
firearms
training
provided
by
u.s.
and
u.k.
government
and
law
enforcement
agencies
facebook
also
is
expanding
its
definition
of
terrorism
to
include
not
just
acts
of
violence
intended
to
achieve
a
political
or
ideological
aim
but
also
attempts
at
violence
especially
when
aimed
at
civilians
with
the
intent
to
coerce
and
intimidate
the
company
has
had
mixed
success
in
its
efforts
to
limit
the
spread
of
extremist
material
on
its
service
facebook
appears
to
have
made
little
progress
for
example
on
its
automated
systems
for
removing
prohibited
content
glorifying
groups
like
the
islamic
state
in
the
four
months
since
the
associated
press
detailed
how
facebook
pages
auto-generated
for
businesses
are
aiding
middle
east
extremists
and
white
supremacists
in
the
u.s.
the
new
details
come
from
an
update
of
a
complaint
to
the
securities
and
exchange
commission
that
the
national
whistleblower
center
plans
to
file
this
week
facebook
said
in
response
that
it
removes
any
auto-generated
pages
that
violate
our
policies
while
we
cannot
catch
every
one
we
remain
vigilant
in
this
effort
monika
bickert
facebook's
head
of
global
policy
management
said
at
the
senate
hearing
that
the
company
has
increased
its
ability
to
detect
terror
violence
and
hate
speech
much
sooner
we
know
that
people
need
to
be
safe
she
said
bickert
noted
that
facebook
removes
any
content
that
promotes
violence
white
supremacy
or
nationalism
as
well
as
indicating
suicide
and
disables
accounts
when
threats
are
detected
twitter's
director
of
public
policy
strategy
nick
pickles
said
the
service
suspended
more
than
million
accounts
for
promoting
terrorism
between
aug
and
dec
more
than
of
the
accounts
are
suspended
through
twitter's
proactive
measures
he
said
not
waiting
for
reports
from
government
and
law
enforcement
sen
rick
scott
r-fla
asked
pickles
why
twitter
hadn't
suspended
the
account
of
venezuelan
socialist
leader
nicolas
maduro
who
has
presided
over
a
deepening
economic
and
political
crisis
and
has
threatened
opposition
politicians
with
criminal
prosecution
if
twitter
removed
maduro's
account
it
would
not
change
facts
on
the
ground
pickles
said
scott
said
he
disagreed
because
maduro's
account
with
some
million
followers
provides
him
with
legitimacy
as
a
world
leader
copyright
the
associated
press
all
rights
reserved
this
material
may
not
be
published
broadcast
rewritten
or
redistributed
